Relevance to PIC 10C:

=======================================================================================================

Notes on why I chose JUCE over Qt:
1) First and the most important reason is that JUCE is a framework that was created for the purpose of
real-time audio processing, while Qt is for more general development.
2) I have been looking into JUCE for about (now that I think about it) half a year now so I am slightly
familiar with how the framework is set up.
3) JUCE's sliders, spin-boxes and other features are similar to Qt's respective features. So, my
understanding of Qt translates rather well to JUCE. Also, JUCE is similar to Qt in that the buttons,
sliders, and sub-content windows are all controlled ultimately by the MainContentComponent. This means
that when the parent object is deleted (the application is closed), the parent releases the dynamically
allocated memory that the child objects store. This is done recursively until every child's memory has
been deleted.

My Struggle (with JUCE):
--> To understand this section you may need to read Research-DSP.txt located in the same directory <--

Preliminaries:
All timing within the application is done in terms of the sample rate, which I will default to 44100 Hz
because there is usually very little need to go above that point (although I notice later that JUCE
defaults to 44100 Hz automatically). Programs created with JUCE are also multi-threaded, i.e. one thread
is used for the GUI of the application and the other is used for the audio processing. Thanks to
Stephanie I know that one thread will need to be locked when I try to send signals between the two or
else I could mis-process the audio signal. By this I mean that the audio thread will probably need to
be locked when I make changes when using the GUI or else changes in the GUI will be interpreted as
instantaneous changes in the audio signal which will cause pops and clicks (I learned about this
phenomenon in Mark Finke's blog post "Making Audio Plugins Part 4: VST and AU Targets" on creating an
audio plug-in, see my "Useful links" for the link). 

While Coding:

Graphics:
-> Organizing the component windows in JUCE is very unintuitive. The removeFromTop and similar member
functions of the Rectangle class not only remove the area of the window that is requested, but also
slide the Rectangle in the direction of the removed area. After some finagling I managed to get the
Rectangle in the right spot, but when resized the rectangle moved away from the center of the GUI. So,
I instead opted for using setCentre and setBounds member functions for organizing my objects, which
appear to offer more control.
-> Once I created the region of the GUI that houses the main spectrum view, I had problems getting the
open, play, pause, and stop buttons to show up on the GUI. To fix this I had set the regions of the
buttons as Rectangle objects and place them in the GUI manually.
-> Creating a GUI is not as painless Qt, since you have to manually place every button on the GUI (as
far as I'm aware). The process of getting the buttons placed so that the GUI resizes correctly is even
more tedious because the every button needs to be placed in terms of the "Local Bounds" or relative to
it's parent component. The nice thing at the end of this entire process is that the application can be
resized if the user so chooses, just by dragging the bottom corner. I did discover that I can turn off
resizing if this becomes an issue later.
-> Drawing graphics in JUCE will always draw relative to the upper right corner (which is in contrast
to when adding to component, which are added at the center), which is slightly confusing.

Coding (Leaks, Linker Errors, Undefined Behavior, etc.)
-> I ran into several memory leaks once I tried to select files to play from my file browser. The
problem was that I had to specify what the known filetypes to the app were, before I could select any
given file.
-> It appears to be audio processing occurs first at the level of audio blocks, which is a collection
(of fixed size) of contiguous samples. Audio processing must happen faster than the application's rate
of receiving audio blocks or else the application will overload/crash/produce erroneous output.
-> I ran into the issue of my project not reacting to button presses (the audio was unchanged, but they
were being toggled). The issue was that I need to inherit from the CallbackListener class, and I then
had to define the virtual function changeCallbackListener so that my mainComponent could be instantiated.
-> I seem to have a habit of forgetting to break out of a switch block.
-> I discovered that my first major bug was a missing lambda function, which means that whenever the
play button was pressed the signal was never sent to start the audio.
-> I had issues getting the sliders to give values that gave a reasonable number of significant digits.
The sliders by default seem to give about 10 digits of precision, which is far too many if I just want
to display through progress through a file.
-> I seem to have a bug when I pause the audio, I can't set the playback to play from the start (I can
only reset it when I'm currently playing). I suspect it has to do with my lack of understanding how the
changeListenerCallback function works. I fixed this issue by creating a specific reaction for pressing
the stop button.
-> It's difficult to access and look at the data that is being processed in each audio block, which
would be very useful to use when debugging the FFT step of my application. I might just put in single
tones (one frequency) and see if the FFT draws a signal that is roughly like a single peak. I may have
to look into windowing, which is a process where a signal is "tapered" (or faded) at both ends which
results in a smoother representation of the signal
-> For some reason the samples seem to be normalized to 100 rather than 1; I realized this after debugging
a single tone for some time.So, I divided each sample by 100 to normalize the buffer.
-> Since the buffer seems to be on average 512 samples long, the GUI could potential re-update at a
frequency of 44100/512 = 86.13 times per second. However, I manually set it to re-update at 10 
frames per second. However, the redrawing function is slow, so the graphics are jagged and laggy. I may
consider interpolating between successive volume levels on each graphic calculation, so this effect is
mitigated.



=======================================================================================================

How I used things from PIC 10C:
-> The onClick member function returns a std::function wrapped function with form void. Thus, it seems
to be customary (from the JUCE website) for the a lambda function to be wrapped having taken its parent
component as a captured value. The code within the lambda function is what's then called on the button
click, which should call another member function of the parent component (i.e. a function within the
same cpp file). The necessary effect of pressing the button should follow.
-> When an audio file is read from a directory, memory for handling the audio is dynamically allocated,
which is handled by a unique_ptr. The information about the file is read (i.e. it's sample rate and
size), which is followed by unique_ptr::release which releases the memory.
-> I learned from homework #1 that you can enumerate values for a variable in C++, so that it only takes
on the specific named values. The JUCE framework sometimes enumerates private variables to make working
with the classes more intuitive.
-> I accidentally messed up a git merge which resulted me in looking some time, luckily I was able to
clone from the remote repository and copy in the files to the point where I just was.
-> Applying the discrete fast Fourier transform was the perfect location to use some generic algorithms
and lambda functions, because each audio block (array) needs to be copied to another array and normalized.
The ability to create and use lambda functions inline makes the process very easy.

